# ğŸ“Š Customer Churn Prediction

Customer Churn Prediction using Logistic Regression and Random Forest (85% Accuracy)

---

## ğŸ“Œ Project Overview
This project predicts customer churn using Machine Learning classification models.

Two models were implemented:
- Logistic Regression
- Random Forest Classifier

The Random Forest model achieved **85% accuracy**, outperforming Logistic Regression (72.5%).

---

## ğŸ“‚ Dataset
- Telco Customer Churn Dataset
- 200 records
- 28 features
- Target Variable: `churn`

---

## âš™ï¸ Technologies Used
- Python
- Pandas
- Scikit-learn
- Matplotlib
- Seaborn
- Google Colab

---

## ğŸ§  Models Implemented

### 1ï¸âƒ£ Logistic Regression
- Accuracy: 72.5%
- Used as baseline model

### 2ï¸âƒ£ Random Forest Classifier
- Accuracy: 85%
- Better performance on classification task
- Handles non-linear relationships effectively

---

## ğŸ“Š Model Evaluation
- Confusion Matrix
- Classification Report
- Accuracy Score

---

## ğŸ“Š Feature Importance

The Random Forest model was used to identify the most influential features contributing to customer churn.

Top influencing factors include:
- Tenure
- Monthly charges
- Service usage patterns
- Contract type related features

This helps businesses focus on key drivers of churn.

---

## ğŸ“ˆ Why Random Forest Performed Better?

- Logistic Regression assumes linear relationship between features and target.
- Random Forest handles non-linear patterns effectively.
- Random Forest reduces overfitting using multiple decision trees.
- It automatically performs feature selection during training.

---

## ğŸš€ Key Learnings
- Data preprocessing
- Train-test split
- Model comparison
- Performance evaluation
- GitHub project deployment

---

## ğŸ‘¨â€ğŸ’» Author
Deepankar  
Aspiring Data Analyst | Machine Learning Enthusiast

---

## ğŸ“¸ Project Output Screenshots

### Confusion Matrix
![Confusion Matrix](Screenshot 2026-02-12 195942.png)

### Logistic Regression Accuracy
![Logistic Accuracy](Screenshot 2026-02-12 200014.png)

### Random Forest Accuracy
![Random Forest Accuracy](Screenshot 2026-02-12 200033.png)

### Feature Importance (Random Forest)
![Feature Importance](Screenshot 2026-02-13 161322.png)

### ğŸ“Š Key Insights from Feature Importance
- Employment status (employ) is the most influential factor.
- Long-distance usage (loglong, longmon, longten) strongly impacts churn.
- Age and tenure also significantly affect customer retention.
- Income and card-related features contribute moderately.
This analysis helps businesses identify high-risk customers and design retention strategies.

### ROC Curve
![ROC Curve](Screenshot 2026-02-13 161529.png)

---

## ğŸ”® Future Improvements
- Hyperparameter tuning
- Cross-validation
- Deploy model using Flask or Streamlit
- Azure ML deployment

---

## ğŸ’¼ Business Recommendations

Based on model insights:

- Focus retention strategies on customers with high long-distance usage.
- Provide loyalty offers for long-tenure customers at risk.
- Offer personalized plans for high-usage customers.
- Monitor employment status segments for churn risk patterns.

Using predictive models like this can help telecom companies reduce revenue loss and improve customer retention.
